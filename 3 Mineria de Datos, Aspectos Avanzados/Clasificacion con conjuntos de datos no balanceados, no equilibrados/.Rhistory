tnr.SMOTEun <- sum(fichero$Class[as.vector(CVperm)] == 1 & knn.pred == 2) / nClass1
tnr.SMOTEun
input <- fichero[-CVperm[,i],-3]
output <- as.factor(fichero[-CVperm[,i], 3])
data<-ubSMOTE(X=input, Y= output, perc.over = 200, perc.under = 200)
newData <- cbind(data$X, data$Y)
classes.train <- newData$`data$Y`
test <- fichero[CVperm[,i],-3]
copitrain <- newData[,-3]
predictions <-  knn(copitrain, test, classes.train, k = 3)
knn.pred <- c(knn.pred, predictions)
tpr.SMOTEun <- sum(fichero$Class[as.vector(CVperm)] == 0 & knn.pred == 1) / nClass0
nClass0
source('~/Dropbox/zMaster/zRStudio/Master-en-Ciencia-De-Datos-e-Ingeniería-de-Computadores-2/3 Mineria de Datos, Aspectos Avanzados/Clasificacion con conjuntos de datos no balanceados, no equilibrados/imbalanceado.R', echo=TRUE)
copitrain %in% input
input %in% copitrain
input[,] %in% copitrain[,]
output
View(newData)
npos <- (1:dim(newData)[1])[newData$`data$Y`==0]
npos
plot(newData$Att1, newData$Att2)
points(newData[newData$`data$Y`==0,1],newData[newData$`data$Y`==0,2],col="red")
points(newData[newData$`data$Y`==1,1],newData[newData$`data$Y`==1,2],col="blue")
source('~/Dropbox/zMaster/zRStudio/Master-en-Ciencia-De-Datos-e-Ingeniería-de-Computadores-2/3 Mineria de Datos, Aspectos Avanzados/Clasificacion con conjuntos de datos no balanceados, no equilibrados/imbalanceado.R', echo=TRUE)
data(ubIonosphere)
n<-ncol(ubIonosphere)
output<-ubIonosphere$Class
input<-ubIonosphere[ ,-n]
data<-ubTomek(X=input, Y= output)
newData<-cbind(data$X, data$Y)
input <- newData[,-3]
library(unbalanced)
fichero <- read.table("subclus.txt", sep=",")
colnames(fichero) <- c("Att1", "Att2", "Class")
#Determinar el radio de imbalanceamiento
nClass0 <- sum(fichero$Class == 0)
nClass1 <- sum(fichero$Class == 1)
IR <- nClass1 / nClass0
IR #Por cada ejemplo positivo hay 5 negativos
#Dividimos el dataset en 5 partes para la validación cruzada
set.seed(1234)
pos <- (1:dim(fichero)[1])[fichero$Class==0]
neg <- (1:dim(fichero)[1])[fichero$Class==1]
#Hacemos las divisiones en los 5 conjuntos de cada clase
CVperm_pos <- matrix(sample(pos,length(pos)), ncol=5, byrow=T)
CVperm_neg <- matrix(sample(neg,length(neg)), ncol=5, byrow=T)
#Unimos las dos clases
CVperm <- rbind(CVperm_pos, CVperm_neg)
output <- as.factor(newData$`data$Y`)
input <- newData[,-3]
data<-ubTomek(X=input, Y= output)
data(ubIonosphere)
n<-ncol(ubIonosphere)
output<-ubIonosphere$Class
output
output <- (newData$`data$Y`)
output
input <- newData[,-3]
data<-ubTomek(X=input, Y= output)
input<-ubIonosphere[ ,-n]
input
View(input)
input <- newData[,-3]
input
library(unbalanced)
fichero <- read.table("subclus.txt", sep=",")
colnames(fichero) <- c("Att1", "Att2", "Class")
#Determinar el radio de imbalanceamiento
nClass0 <- sum(fichero$Class == 0)
nClass1 <- sum(fichero$Class == 1)
IR <- nClass1 / nClass0
IR #Por cada ejemplo positivo hay 5 negativos
#Dividimos el dataset en 5 partes para la validación cruzada
set.seed(1234)
pos <- (1:dim(fichero)[1])[fichero$Class==0]
neg <- (1:dim(fichero)[1])[fichero$Class==1]
#Hacemos las divisiones en los 5 conjuntos de cada clase
CVperm_pos <- matrix(sample(pos,length(pos)), ncol=5, byrow=T)
CVperm_neg <- matrix(sample(neg,length(neg)), ncol=5, byrow=T)
#Unimos las dos clases
CVperm <- rbind(CVperm_pos, CVperm_neg)
input <- fichero[,-3]
output <- as.factor(fichero[,3])
data<-ubSMOTE(X=input, Y= output, perc.over = 100, perc.under = 200)
newData<-cbind(data$X, data$Y)
nClass0nuevos <- sum(newData$`data$Y` == 0)
nClass1nuevos <- sum(newData$`data$Y` == 1)
IR <- nClass1nuevos / nClass0nuevos
IR #Por cada ejemplo positivo hay 1 negativos
#Visualizamos la distribución de los datos
plot(newData$Att1, newData$Att2)
points(newData[newData$`data$Y`==0,1],newData[newData$`data$Y`==0,2],col="red")
points(newData[newData$`data$Y`==1,1],newData[newData$`data$Y`==1,2],col="blue")
library(unbalanced)
fichero <- read.table("subclus.txt", sep=",")
colnames(fichero) <- c("Att1", "Att2", "Class")
#Determinar el radio de imbalanceamiento
nClass0 <- sum(fichero$Class == 0)
nClass1 <- sum(fichero$Class == 1)
IR <- nClass1 / nClass0
IR #Por cada ejemplo positivo hay 5 negativos
#Dividimos el dataset en 5 partes para la validación cruzada
set.seed(1234)
pos <- (1:dim(fichero)[1])[fichero$Class==0]
neg <- (1:dim(fichero)[1])[fichero$Class==1]
#Hacemos las divisiones en los 5 conjuntos de cada clase
CVperm_pos <- matrix(sample(pos,length(pos)), ncol=5, byrow=T)
CVperm_neg <- matrix(sample(neg,length(neg)), ncol=5, byrow=T)
#Unimos las dos clases
CVperm <- rbind(CVperm_pos, CVperm_neg)
input <- fichero[,-3]
output <- as.factor(fichero[,3])
data<-ubSMOTE(X=input, Y= output, perc.over = 100, perc.under = 200)
newData<-cbind(data$X, data$Y)
nClass0nuevos <- sum(newData$`data$Y` == 0)
nClass1nuevos <- sum(newData$`data$Y` == 1)
IR <- nClass1nuevos / nClass0nuevos
IR #Por cada ejemplo positivo hay 1 negativos
#Visualizamos la distribución de los datos
plot(newData$Att1, newData$Att2)
points(newData[newData$`data$Y`==0,1],newData[newData$`data$Y`==0,2],col="red")
points(newData[newData$`data$Y`==1,1],newData[newData$`data$Y`==1,2],col="blue")
knn.pred <- NULL
set.seed(1234)
for (i in 1:5){
input <- fichero[-CVperm[,i],-3]
output <- as.factor(fichero[-CVperm[,i], 3])
data<-ubSMOTE(X=input, Y= output, perc.over = 200, perc.under = 200)
newData <- cbind(data$X, data$Y)
classes.train <- newData$`data$Y`
test <- fichero[CVperm[,i],-3]
copitrain <- newData[,-3]
plot(newData$Att1, newData$Att2,title(i))
points(newData[newData$`data$Y`==0,1],newData[newData$`data$Y`==0,2],col="red")
points(newData[newData$`data$Y`==1,1],newData[newData$`data$Y`==1,2],col="blue")
predictions <-  knn(copitrain, test, classes.train, k = 3)
knn.pred <- c(knn.pred, predictions)
}
tpr.SMOTEun <- sum(fichero$Class[as.vector(CVperm)] == 0 & knn.pred == 1) / nClass0
tpr.SMOTEun
#Obtenemos un 0.88 en la clase positiva en la clase positiva
tnr.SMOTEun <- sum(fichero$Class[as.vector(CVperm)] == 1 & knn.pred == 2) / nClass1
tnr.SMOTEun
#Obtenemos un 0.948 en la clase negativa
gmean.SMOTEun <- sqrt(tpr.SMOTEun * tnr.SMOTEun)
gmean.SMOTEun
#La media es de un 0.913
output <- newData$`data$Y`
input <- newData[,-3]
data<-ubTomek(X=input, Y= output)
newData
tomelinks=TRUE
set.seed(1234)
tomelinks=TRUE
for (i in 1:5){
input <- fichero[-CVperm[,i],-3]
output <- as.factor(fichero[-CVperm[,i], 3])
data<-ubSMOTE(X=input, Y= output, perc.over = 200, perc.under = 200)
newData <- cbind(data$X, data$Y)
classes.train <- newData$`data$Y`
test <- fichero[CVperm[,i],-3]
copitrain <- newData[,-3]
if (tomelinks==TRUE){
#Tomelinks
output <- newData$`data$Y`
input <- newData[,-3]
data<-ubTomek(X=input, Y= output)
}
plot(newData$Att1, newData$Att2,title(i))
points(newData[newData$`data$Y`==0,1],newData[newData$`data$Y`==0,2],col="red")
points(newData[newData$`data$Y`==1,1],newData[newData$`data$Y`==1,2],col="blue")
predictions <-  knn(copitrain, test, classes.train, k = 3)
knn.pred <- c(knn.pred, predictions)
}
SMOTEUnbalanced = function(tomelinks=FALSE){
for (i in 1:5){
input <- fichero[-CVperm[,i],-3]
output <- as.factor(fichero[-CVperm[,i], 3])
data<-ubSMOTE(X=input, Y= output, perc.over = 200, perc.under = 200)
newData <- cbind(data$X, data$Y)
classes.train <- newData$`data$Y`
test <- fichero[CVperm[,i],-3]
copitrain <- newData[,-3]
if (tomelinks==TRUE){
#Tomelinks
output <- newData$`data$Y`
input <- newData[,-3]
data<-ubTomek(X=input, Y= output)
}
plot(newData$Att1, newData$Att2,title(i))
points(newData[newData$`data$Y`==0,1],newData[newData$`data$Y`==0,2],col="red")
points(newData[newData$`data$Y`==1,1],newData[newData$`data$Y`==1,2],col="blue")
predictions <-  knn(copitrain, test, classes.train, k = 3)
knn.pred <- c(knn.pred, predictions)
}
}
source('~/Dropbox/zMaster/zRStudio/Master-en-Ciencia-De-Datos-e-Ingeniería-de-Computadores-2/3 Mineria de Datos, Aspectos Avanzados/Clasificacion con conjuntos de datos no balanceados, no equilibrados/imbalanceado.R', echo=TRUE)
source('~/Dropbox/zMaster/zRStudio/Master-en-Ciencia-De-Datos-e-Ingeniería-de-Computadores-2/3 Mineria de Datos, Aspectos Avanzados/Clasificacion con conjuntos de datos no balanceados, no equilibrados/imbalanceado.R', echo=TRUE)
knn.pred <- NULL
tomelinks=TRUE
SMOTEUnbalanced = function(tomelinks=FALSE){
for (i in 1:5){
input <- fichero[-CVperm[,i],-3]
output <- as.factor(fichero[-CVperm[,i], 3])
data<-ubSMOTE(X=input, Y= output, perc.over = 200, perc.under = 200)
newData <- cbind(data$X, data$Y)
classes.train <- newData$`data$Y`
test <- fichero[CVperm[,i],-3]
copitrain <- newData[,-3]
if (tomelinks==TRUE){
#Tomelinks
output <- newData$`data$Y`
input <- newData[,-3]
data<-ubTomek(X=input, Y= output)
newData <- cbind(data$X, data$Y)
classes.train <- newData$`data$Y`
copitrain <- newData[,3]
}
plot(newData$Att1, newData$Att2,title(i))
points(newData[newData$`data$Y`==0,1],newData[newData$`data$Y`==0,2],col="red")
points(newData[newData$`data$Y`==1,1],newData[newData$`data$Y`==1,2],col="blue")
predictions <-  knn(copitrain, test, classes.train, k = 3)
knn.pred <- c(knn.pred, predictions)
}
return(knn.pred)
}
set.seed(1234)
SMOTEUnbalanced(FALSE)
tpr.SMOTEun <- sum(fichero$Class[as.vector(CVperm)] == 0 & knn.pred == 1) / nClass0
tpr.SMOTEun
#Obtenemos un 0.88 en la clase positiva en la clase positiva
tnr.SMOTEun <- sum(fichero$Class[as.vector(CVperm)] == 1 & knn.pred == 2) / nClass1
tnr.SMOTEun
#Obtenemos un 0.948 en la clase negativa
gmean.SMOTEun <- sqrt(tpr.SMOTEun * tnr.SMOTEun)
gmean.SMOTEun
#La media es de un 0.913
set.seed(1234)
knn.pred <- SMOTEUnbalanced(FALSE)
tpr.SMOTEun <- sum(fichero$Class[as.vector(CVperm)] == 0 & knn.pred == 1) / nClass0
tpr.SMOTEun
#Obtenemos un 0.88 en la clase positiva en la clase positiva
tnr.SMOTEun <- sum(fichero$Class[as.vector(CVperm)] == 1 & knn.pred == 2) / nClass1
tnr.SMOTEun
#Obtenemos un 0.948 en la clase negativa
gmean.SMOTEun <- sqrt(tpr.SMOTEun * tnr.SMOTEun)
gmean.SMOTEun
#La media es de un 0.913
set.seed(1234)
knn.pred <- SMOTEUnbalanced(TRUE)
SMOTEUnbalanced = function(tomelinks=FALSE){
for (i in 1:5){
input <- fichero[-CVperm[,i],-3]
output <- as.factor(fichero[-CVperm[,i], 3])
data<-ubSMOTE(X=input, Y= output, perc.over = 200, perc.under = 200)
newData <- cbind(data$X, data$Y)
classes.train <- newData$`data$Y`
test <- fichero[CVperm[,i],-3]
copitrain <- newData[,-3]
if (tomelinks==TRUE){
#Tomelinks
output <- newData$`data$Y`
input <- newData[,-3]
data<-ubTomek(X=input, Y= output)
newData <- cbind(data$X, data$Y)
classes.train <- newData$`data$Y`
copitrain <- newData[,-3]
}
plot(newData$Att1, newData$Att2,title(i))
points(newData[newData$`data$Y`==0,1],newData[newData$`data$Y`==0,2],col="red")
points(newData[newData$`data$Y`==1,1],newData[newData$`data$Y`==1,2],col="blue")
predictions <-  knn(copitrain, test, classes.train, k = 3)
knn.pred <- c(knn.pred, predictions)
}
return(knn.pred)
}
set.seed(1234)
knn.pred <- SMOTEUnbalanced(TRUE)
tpr.SMOTEun <- sum(fichero$Class[as.vector(CVperm)] == 0 & knn.pred == 1) / nClass0
tpr.SMOTEun
knn.pred=NULL
set.seed(1234)
knn.pred <- SMOTEUnbalanced(TRUE)
tpr.SMOTEun <- sum(fichero$Class[as.vector(CVperm)] == 0 & knn.pred == 1) / nClass0
tpr.SMOTEun
#Obtenemos un 0.88 en la clase positiva en la clase positiva
tnr.SMOTEun <- sum(fichero$Class[as.vector(CVperm)] == 1 & knn.pred == 2) / nClass1
tnr.SMOTEun
#Obtenemos un 0.948 en la clase negativa
gmean.SMOTEun <- sqrt(tpr.SMOTEun * tnr.SMOTEun)
gmean.SMOTEun
#La media es de un 0.913
i=1
input <- fichero[-CVperm[,i],-3]
tomelinks=TRUE
input <- fichero[-CVperm[,i],-3]
output <- as.factor(fichero[-CVperm[,i], 3])
data<-ubSMOTE(X=input, Y= output, perc.over = 200, perc.under = 200)
newData <- cbind(data$X, data$Y)
classes.train <- newData$`data$Y`
test <- fichero[CVperm[,i],-3]
copitrain <- newData[,-3]
if (tomelinks==TRUE){
#Tomelinks
output <- newData$`data$Y`
input <- newData[,-3]
data<-ubTomek(X=input, Y= output)
newData <- cbind(data$X, data$Y)
classes.train <- newData$`data$Y`
copitrain <- newData[,-3]
}
source('~/Dropbox/zMaster/zRStudio/Master-en-Ciencia-De-Datos-e-Ingeniería-de-Computadores-2/3 Mineria de Datos, Aspectos Avanzados/Clasificacion con conjuntos de datos no balanceados, no equilibrados/imbalanceado.R', echo=TRUE)
n<-ncol(ubIonosphere)
output<-ubIonosphere$Class
data(ubIonosphere)
n<-ncol(ubIonosphere)
output<-ubIonosphere$Class
input<-ubIonosphere[ ,-n]
data<-ubENN(X=input, Y= output)
newData<-cbind(data$X, data$Y)
output <- newData$
tomelinks=FALSE;enn=FALSE
tomelinks=FALSE; enn=FALSE
source('~/Dropbox/zMaster/zRStudio/Master-en-Ciencia-De-Datos-e-Ingeniería-de-Computadores-2/3 Mineria de Datos, Aspectos Avanzados/Clasificacion con conjuntos de datos no balanceados, no equilibrados/imbalanceado.R', echo=TRUE)
knn.pred=NULL
set.seed(1234)
knn.pred <- SMOTEUnbalanced(FALSE,TRUE)
tpr.SMOTEun <- sum(fichero$Class[as.vector(CVperm)] == 0 & knn.pred == 1) / nClass0
tpr.SMOTEun
#Obtenemos un 0.88 en la clase positiva en la clase positiva
tnr.SMOTEun <- sum(fichero$Class[as.vector(CVperm)] == 1 & knn.pred == 2) / nClass1
tnr.SMOTEun
gmean.SMOTEun <- sqrt(tpr.SMOTEun * tnr.SMOTEun)
gmean.SMOTEun
set.seed(1234)
knn.pred <- SMOTEUnbalanced()
knn.pred=NULL
set.seed(1234)
knn.pred <- SMOTEUnbalanced()
tpr.SMOTEun <- sum(fichero$Class[as.vector(CVperm)] == 0 & knn.pred == 1) / nClass0
tpr.SMOTEun
#Obtenemos un 0.88 en la clase positiva en la clase positiva
tnr.SMOTEun <- sum(fichero$Class[as.vector(CVperm)] == 1 & knn.pred == 2) / nClass1
tnr.SMOTEun
#Obtenemos un 0.948 en la clase negativa
gmean.SMOTEun <- sqrt(tpr.SMOTEun * tnr.SMOTEun)
gmean.SMOTEun
#La media es de un 0.913
knn.pred=NULL
set.seed(1234)
knn.pred <- SMOTEUnbalanced(TRUE)
tpr.SMOTEun <- sum(fichero$Class[as.vector(CVperm)] == 0 & knn.pred == 1) / nClass0
tpr.SMOTEun
#Obtenemos un 0.88 en la clase positiva en la clase positiva
tnr.SMOTEun <- sum(fichero$Class[as.vector(CVperm)] == 1 & knn.pred == 2) / nClass1
tnr.SMOTEun
#Obtenemos un 0.948 en la clase negativa
gmean.SMOTEun <- sqrt(tpr.SMOTEun * tnr.SMOTEun)
gmean.SMOTEun
#La media es de un 0.913
knn.pred=NULL
set.seed(1234)
knn.pred <- SMOTEUnbalanced(FALSE,TRUE)
tpr.SMOTEun <- sum(fichero$Class[as.vector(CVperm)] == 0 & knn.pred == 1) / nClass0
tpr.SMOTEun
#Obtenemos un 0.73 en la clase positiva en la clase positiva
tnr.SMOTEun <- sum(fichero$Class[as.vector(CVperm)] == 1 & knn.pred == 2) / nClass1
tnr.SMOTEun
#Obtenemos un 0.97 en la clase negativa
gmean.SMOTEun <- sqrt(tpr.SMOTEun * tnr.SMOTEun)
gmean.SMOTEun
#La media es de un 0.841
library(unbalanced)
fichero <- read.table("circle.txt", sep=",")
colnames(fichero) <- c("Att1", "Att2", "Class")
#Determinar el radio de imbalanceamiento
nClass0 <- sum(fichero$Class == 0)
nClass1 <- sum(fichero$Class == 1)
IR <- nClass1 / nClass0
IR #Por cada ejemplo positivo hay 5 negativos
#Dividimos el dataset en 5 partes para la validación cruzada
set.seed(1234)
pos <- (1:dim(fichero)[1])[fichero$Class==0]
neg <- (1:dim(fichero)[1])[fichero$Class==1]
#Hacemos las divisiones en los 5 conjuntos de cada clase
CVperm_pos <- matrix(sample(pos,length(pos)), ncol=5, byrow=T)
CVperm_neg <- matrix(sample(neg,length(neg)), ncol=5, byrow=T)
#Unimos las dos clases
CVperm <- rbind(CVperm_pos, CVperm_neg)
input <- fichero[,-3]
output <- as.factor(fichero[,3])
data<-ubSMOTE(X=input, Y= output, perc.over = 100, perc.under = 200)
newData<-cbind(data$X, data$Y)
nClass0nuevos <- sum(newData$`data$Y` == 0)
nClass1nuevos <- sum(newData$`data$Y` == 1)
IR <- nClass1nuevos / nClass0nuevos
IR #Por cada ejemplo positivo hay 1 negativos
#Visualizamos la distribución de los datos
plot(newData$Att1, newData$Att2)
points(newData[newData$`data$Y`==0,1],newData[newData$`data$Y`==0,2],col="red")
points(newData[newData$`data$Y`==1,1],newData[newData$`data$Y`==1,2],col="blue")
knn.pred=NULL
set.seed(1234)
knn.pred <- SMOTEUnbalanced()
SMOTEUnbalanced = function(tomelinks=FALSE,enn=FALSE){
for (i in 1:5){
input <- fichero[-CVperm[,i],-3]
output <- as.factor(fichero[-CVperm[,i], 3])
data<-ubSMOTE(X=input, Y= output, perc.over = 200, perc.under = 200)
newData <- cbind(data$X, data$Y)
classes.train <- newData$`data$Y`
test <- fichero[CVperm[,i],-3]
copitrain <- newData[,-3]
if (tomelinks==TRUE){
#Tomelinks
output <- newData$`data$Y`
input <- newData[,-3]
data<-ubTomek(X=input, Y= output)
newData <- cbind(data$X, data$Y)
classes.train <- newData$`data$Y`
copitrain <- newData[,-3]
} else if (enn==TRUE){
data<-ubENN(X=input, Y= output)
newData<-cbind(data$X, data$Y)
classes.train <- newData$`data$Y`
copitrain <- newData[,-3]
}
plot(newData$Att1, newData$Att2,title(i))
points(newData[newData$`data$Y`==0,1],newData[newData$`data$Y`==0,2],col="red")
points(newData[newData$`data$Y`==1,1],newData[newData$`data$Y`==1,2],col="blue")
predictions <-  knn(copitrain, test, classes.train, k = 3)
knn.pred <- c(knn.pred, predictions)
}
return(knn.pred)
}
knn.pred <- SMOTEUnbalanced()
tpr.SMOTEun <- sum(fichero$Class[as.vector(CVperm)] == 0 & knn.pred == 1) / nClass0
tpr.SMOTEun
#Obtenemos un 0.88 en la clase positiva en la clase positiva
#Obtenemos un 0.836 en la clase positiva en la clase positiva
tnr.SMOTEun <- sum(fichero$Class[as.vector(CVperm)] == 1 & knn.pred == 2) / nClass1
tnr.SMOTEun
gmean.SMOTEun <- sqrt(tpr.SMOTEun * tnr.SMOTEun)
gmean.SMOTEun
knn.pred=NULL
set.seed(1234)
knn.pred <- SMOTEUnbalanced(TRUE)
tpr.SMOTEun <- sum(fichero$Class[as.vector(CVperm)] == 0 & knn.pred == 1) / nClass0
tpr.SMOTEun
tnr.SMOTEun <- sum(fichero$Class[as.vector(CVperm)] == 1 & knn.pred == 2) / nClass1
tnr.SMOTEun
gmean.SMOTEun <- sqrt(tpr.SMOTEun * tnr.SMOTEun)
gmean.SMOTEun
knn.pred=NULL
set.seed(1234)
knn.pred <- SMOTEUnbalanced(FALSE,TRUE)
tpr.SMOTEun <- sum(fichero$Class[as.vector(CVperm)] == 0 & knn.pred == 1) / nClass0
tpr.SMOTEun
tnr.SMOTEun <- sum(fichero$Class[as.vector(CVperm)] == 1 & knn.pred == 2) / nClass1
tnr.SMOTEun
gmean.SMOTEun <- sqrt(tpr.SMOTEun * tnr.SMOTEun)
gmean.SMOTEun
source('~/Dropbox/zMaster/zRStudio/Master-en-Ciencia-De-Datos-e-Ingeniería-de-Computadores-2/3 Mineria de Datos, Aspectos Avanzados/Clasificacion con conjuntos de datos no balanceados, no equilibrados/imbalanceado.R', echo=TRUE)
input <- fichero[,-3]
output <- as.factor(fichero[,3])
data<-ubSMOTE(X=input, Y= output, perc.over = 100, perc.under = 200)
newData<-cbind(data$X, data$Y)
nClass0nuevos <- sum(newData$`data$Y` == 0)
nClass1nuevos <- sum(newData$`data$Y` == 1)
IR <- nClass1nuevos / nClass0nuevos
IR #Por cada ejemplo positivo hay 1 negativos
data<-ubSMOTE(X=input, Y= output, perc.over = 100, perc.under = 100)
newData<-cbind(data$X, data$Y)
nClass0nuevos <- sum(newData$`data$Y` == 0)
nClass1nuevos <- sum(newData$`data$Y` == 1)
data<-ubSMOTE(X=input, Y= output, perc.over = 100, perc.under = 50)
newData<-cbind(data$X, data$Y)
nClass0nuevos <- sum(newData$`data$Y` == 0)
nClass1nuevos <- sum(newData$`data$Y` == 1)
IR <- nClass1nuevos / nClass0nuevos
IR #Por cada ejemplo positivo hay 1 negativos
nClass0 <- sum(fichero$Class == 0)
nClass1 <- sum(fichero$Class == 1)
data<-ubSMOTE(X=input, Y= output, perc.over = 100, perc.under = 60)
newData<-cbind(data$X, data$Y)
nClass0nuevos <- sum(newData$`data$Y` == 0)
data<-ubSMOTE(X=input, Y= output, perc.over = 100, perc.under = 100)
newData<-cbind(data$X, data$Y)
nClass0nuevos <- sum(newData$`data$Y` == 0)
data<-ubSMOTE(X=input, Y= output, perc.over = 10, perc.under = 100)
newData<-cbind(data$X, data$Y)
nClass0nuevos <- sum(newData$`data$Y` == 0)
nClass1nuevos <- sum(newData$`data$Y` == 1)
data<-ubSMOTE(X=input, Y= output, perc.over = 100, perc.under = 100)
newData<-cbind(data$X, data$Y)
nClass0nuevos <- sum(newData$`data$Y` == 0)
nClass1nuevos <- sum(newData$`data$Y` == 1)
data<-ubSMOTE(X=input, Y= output, perc.over = 100, perc.under = 10)
newData<-cbind(data$X, data$Y)
nClass0nuevos <- sum(newData$`data$Y` == 0)
nClass1nuevos <- sum(newData$`data$Y` == 1)
data<-ubSMOTE(X=input, Y= output, perc.over = 200, perc.under = 100)
newData<-cbind(data$X, data$Y)
nClass0nuevos <- sum(newData$`data$Y` == 0)
nClass1nuevos <- sum(newData$`data$Y` == 1)
data<-ubSMOTE(X=input, Y= output, perc.over = 100, perc.under = 200)
newData<-cbind(data$X, data$Y)
nClass0nuevos <- sum(newData$`data$Y` == 0)
nClass1nuevos <- sum(newData$`data$Y` == 1)
IR <- nClass1nuevos / nClass0nuevos
IR #Por cada ejemplo positivo hay 1 negativos
