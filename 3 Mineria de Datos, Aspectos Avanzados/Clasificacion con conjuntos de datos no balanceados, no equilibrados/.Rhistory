# Mostramos un gr?fico de puntos con la funci?n plot
# Vemos que hay dos outliers
# Aplicamos el test de Grubbs sobre datos.con.dos.outliers.masking
# [1] 0.05614091
# El resultado no es significativo con ninguno de los valores de alpha usuales (<= 0.05)
# Sin embargo, hay dos outliers. (125, 154).
# La raz?n es que se ha producido un efecto de "masking"
# Ning?n outlier es detectado por Grubbs :-(
mydata.numeric = datos.con.dos.outliers.masking
plot(mydata.numeric)
test.de.Grubbs = grubbs.test(mydata.numeric, two.sided = TRUE)
test.de.Grubbs$p.value
MiPlot_resultados_TestGrubbs(mydata.numeric)
###########################################################################
# Test de Rosner
###########################################################################
# Hay tests para detectar un n?mero exacto de k outliers, pero no son muy ?tiles
# Mejor usamos un test para detectar un n?mero menor o igual que k outliers (Rosner)
# Transparencia 81
# Aplicamos el Test de Rosner (rosnerTest) con k=4 sobre datos.con.dos.outliers.masking
# Nos dar? un aviso ocasionado por tener pocos datos
# Guardamos el resultado en test.de.rosner
# El test ordena los valores de mayor a menor distancia de la media y lanza el test de hip?tesis
# para ver si hay menos de k=4 outliers.
# Imprimimos los siguientes campos:
#   test.de.rosner$all.stats$Outlier
#     Es un vector de 4 boolean.
#     Nos indica si son considerados outliers los 4 valores que m?s se alejan de la media
#     En este caso:
#     [1]  TRUE  TRUE FALSE FALSE
#     Los dos primeros son TRUE y el resto FALSE => El test indica que hay dos outliers :-)
#
#   test.de.rosner$all.stats$Obs.Num
#     Es un vector con los cuatro ?ndices de los 4 valores que
#     m?s se alejan de la media
#     En este caso:
#     [1]  10    11   5     4
# Construimos el vector con los ?ndices de los que son outliers (10, 11)
# y se lo pasamos como par?metro a la funci?n
# MiPlot_Univariate_Outliers
# MiPlot_Univariate_Outliers = function (datos, indices_de_Outliers, titulo){
# N?mero de datos: 12
# ?Qui?n es outlier?: FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE TRUE TRUE FALSE
mydata.numeric = datos.con.dos.outliers.masking
test.de.rosner = rosnerTest(mydata.numeric, k=4)
is.outlier.rosner = test.de.rosner$all.stats$Outlier
k.mayores.desviaciones.de.la.media = test.de.rosner$all.stats$Obs.Num
indices.de.outliers.rosner = k.mayores.desviaciones.de.la.media[is.outlier.rosner]
valores.de.outliers.rosner = mydata.numeric[indices.de.outliers.rosner]
print("?ndices de las k-mayores desviaciones de la media")
k.mayores.desviaciones.de.la.media
print("De los k valores fijados, ?Qui?n es outlier?")
is.outlier.rosner
print("Los ?ndices de los outliers son:")
indices.de.outliers.rosner
print("Los valores de los outliers son:")
valores.de.outliers.rosner
MiPlot_Univariate_Outliers (mydata.numeric, indices.de.outliers.rosner, "Test de Rosner")
#######################################################################
# La funci?n
# MiPlot_resultados_TestRosner = function(datos)
# hace directamente las anteriores tareas, es decir, lanza el test y dibuja el plot.
# Lanzamos esta funci?n con el dataset datos.con.dos.outliers.masking
# y comprobamos que ofrece los resultados vistos anteriormente
mydata.numeric = datos.con.dos.outliers.masking
MiPlot_resultados_TestRosner(mydata.numeric)
#######################################################################
# Para ver el comportamiento del Test de Rosner con el conjunto de datos inicial
# lanzamos la funci?n MiPlot_resultados_TestRosner con k=4 sobre datos.con.un.outlier
# Test de Rosner
# ?ndices de las k-mayores desviaciones de la media: 10 5 4 7
# De las k mayores desviaciones, ?Qui?n es outlier? TRUE FALSE FALSE FALSE
# Los ?ndices de los outliers son: 10
# Los valores de los outliers son: 140
# N?mero de datos: 11
# ?Qui?n es outlier?: FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE TRUE FALSE
# El test indica que s?lo hay un outlier :-)
mydata.numeric = datos.con.un.outlier
MiPlot_resultados_TestRosner(mydata.numeric)
#######################################################################
# Lanzamos tambi?n el test de Rosner con k=4 sobre datos.con.varios.outliers
# Mostamos el plot de datos.con.varios.outliers
# Aplicamos el Test de Rosner (rosnerTest) con k=4 sobre datos.con.varios.outliers
# [1]  TRUE  TRUE  TRUE FALSE
# [1] 54 53 52 51
# Indica que hay tres outliers :-)
mydata.numeric = datos.con.varios.outliers
MiPlot_resultados_TestRosner(mydata.numeric)
source('~/Dropbox/zMaster/zRStudio/MDA/!GuiÛnPr·cticas_Outliers_B1_1Variate_IQR.R', echo=TRUE)
# M?ster -> Detecci?n de anomal?as
# Juan Carlos Cubero. Universidad de Granada
###########################################################################
# MULTIVARIATE STATISTICAL OUTLIERS -> Multivariate Normal Distribution --> Mahalanobis
###########################################################################
# Los outliers son respecto a un conjunto de variables.
# Un registro ser? un outlier porque tenga un valor an?malo en alguna variable
# o porque tenga una combinaci?n an?mala de valores.
# Necesita:
# mydata.numeric
# mydata.numeric.scaled
# Trabajamos sobre mtcars[,-c(8:11)]
mydata.numeric = mtcars[,-c(8:11)]
mydata.numeric.scaled = scale(mydata.numeric)
###########################################################################
# Paquete mvoutlier
###########################################################################
###########################################################################
# Obtenci?n de los outliers multivariantes
# Transparencia 95
#
# Calcula los outliers calculando las distancias de Mahalanobis y usando la aproximaci?n de la Chi cuadrado
# La estimaci?n de la matriz de covarianzas es la estimaci?n robusta seg?n MCD
# No hay que normalizar los datos ya que la distancia de Mahalanobis est?
# dise?ada, precisamente para evitar el problema de la escala.
# uni.plot genera el gr?fico similar a MiPlot_Univariate_Outliers con todas las columnas
# Adem?s, devuelve en $outliers los ?ndices de los outliers
# Establecemos los valores de significaci?n
# alpha.value.penalizado es para tener en cuenta el error FWER
alpha.value = 0.05
alpha.value.penalizado = 1 - ( 1 - alpha.value) ^ (1 / nrow(mydata.numeric))       # Transparencia 91
# Establecemos la semilla para el m?todo iterativo que calcula MCD
set.seed(12)
# Llamamos a uni.plot del paquete mvoutlier con symb=FALSE, alpha = alpha.value.penalizado
# Guardamos el resultado en la variable mvoutlier.plot
# Esta funci?n calcula los outliers MULTIVARIANTES seg?n la distancia de Mahalanobis
# considerando la estimaci?n robusta de la matriz de covarianzas -MCD- y la estimaci?n robusta de la media de cada variable.
# Tambi?n imprime un plot 1-dimensional para ver los valores que toman los outliers en cada atributo
# pero el plot no imprime las etiquetas de los outliers
# Nota: Es posible que haya que instalar el paquete pcaPP para que se pueda ejecutar uni.plot
X11()
# COMPLETAR
mvoutlier.plot <- uni.plot(mydata.numeric,symb=FALSE,alpha = alpha.value.penalizado)
is.MCD.outlier <- mvoutlier.plot$outliers
is.MCD.outlier
numero.de.outliers.MCD <- sum(is.MCD.outlier)
numero.de.outliers.MCD
data.frame.solo.outliers <- mydata.numeric.scaled[is.MCD.outlier]
data.frame.solo.outliers
data.frame.solo.outliers <- mydata.numeric.scaled[is.MCD.outlier,]
data.frame.solo.outliers
MiBoxPlot_juntos(mydata.numeric,is.MCD.outlier)
MiBiPlot_Multivariate_Outliers(mydata.numeric,is.MCD.outlier,"Titulo")
MiPlot_Univariate_Outliers(mydata.numeric,is.MCD.outlier,"Titulo")
indices.de.interes <- which(rownames(mydata.numeric) == "Ferrari Dino")
MiPlot_Univariate_Outliers(mydata.numeric,indices.de.interes,"Titulo")
indices.de.interes
data.frame.solo.outliers
# Apéndice glm
library(rgl)
#' @param new.device a logical value. If TRUE, creates a new device
#' @param bg the background color of the device
#' @param width the width of the device
rgl_init <- function(new.device = FALSE, bg = "white", width = 640) {
if( new.device | rgl.cur() == 0 ) {
rgl.open()
par3d(windowRect = 50 + c( 0, 0, width, width ) )
rgl.bg(color = bg )
}
rgl.clear(type = c("shapes", "bboxdeco"))
rgl.viewpoint(theta = 15, phi = 20, zoom = 0.7)
}
# x, y, z : numeric vectors corresponding to
#  the coordinates of points
# axis.col : axis colors
# xlab, ylab, zlab: axis labels
# show.plane : add axis planes
# show.bbox : add the bounding box decoration
# bbox.col: the bounding box colors. The first color is the
# the background color; the second color is the color of tick marks
rgl_add_axes <- function(x, y, z, axis.col = "grey",
xlab = "", ylab="", zlab="", show.plane = TRUE,
show.bbox = FALSE, bbox.col = c("#333377","black"))
{
lim <- function(x){c(-max(abs(x)), max(abs(x))) * 1.1}
# Add axes
xlim <- lim(x); ylim <- lim(y); zlim <- lim(z)
rgl.lines(xlim, c(0, 0), c(0, 0), color = axis.col)
rgl.lines(c(0, 0), ylim, c(0, 0), color = axis.col)
rgl.lines(c(0, 0), c(0, 0), zlim, color = axis.col)
# Add a point at the end of each axes to specify the direction
axes <- rbind(c(xlim[2], 0, 0), c(0, ylim[2], 0),
c(0, 0, zlim[2]))
rgl.points(axes, color = axis.col, size = 3)
# Add axis labels
rgl.texts(axes, text = c(xlab, ylab, zlab), color = axis.col,
adj = c(0.5, -0.8), size = 2)
# Add plane
if(show.plane)
xlim <- xlim/1.1; zlim <- zlim /1.1
rgl.quads( x = rep(xlim, each = 2), y = c(0, 0, 0, 0),
z = c(zlim[1], zlim[2], zlim[2], zlim[1]))
# Add bounding box decoration
library(rgl)
#' @param new.device a logical value. If TRUE, creates a new device
#' @param bg the background color of the device
#' @param width the width of the device
rgl_init <- function(new.device = FALSE, bg = "white", width = 640) {
if( new.device | rgl.cur() == 0 ) {
rgl.open()
par3d(windowRect = 50 + c( 0, 0, width, width ) )
rgl.bg(color = bg )
}
rgl.clear(type = c("shapes", "bboxdeco"))
rgl.viewpoint(theta = 15, phi = 20, zoom = 0.7)
}
# x, y, z : numeric vectors corresponding to
#  the coordinates of points
# axis.col : axis colors
# xlab, ylab, zlab: axis labels
# show.plane : add axis planes
# show.bbox : add the bounding box decoration
# bbox.col: the bounding box colors. The first color is the
# the background color; the second color is the color of tick marks
rgl_add_axes <- function(x, y, z, axis.col = "grey",
xlab = "", ylab="", zlab="", show.plane = TRUE,
show.bbox = FALSE, bbox.col = c("#333377","black"))
{
lim <- function(x){c(-max(abs(x)), max(abs(x))) * 1.1}
# Add axes
xlim <- lim(x); ylim <- lim(y); zlim <- lim(z)
rgl.lines(xlim, c(0, 0), c(0, 0), color = axis.col)
rgl.lines(c(0, 0), ylim, c(0, 0), color = axis.col)
rgl.lines(c(0, 0), c(0, 0), zlim, color = axis.col)
# Add a point at the end of each axes to specify the direction
axes <- rbind(c(xlim[2], 0, 0), c(0, ylim[2], 0),
c(0, 0, zlim[2]))
rgl.points(axes, color = axis.col, size = 3)
# Add axis labels
rgl.texts(axes, text = c(xlab, ylab, zlab), color = axis.col,
adj = c(0.5, -0.8), size = 2)
# Add plane
if(show.plane)
xlim <- xlim/1.1; zlim <- zlim /1.1
rgl.quads( x = rep(xlim, each = 2), y = c(0, 0, 0, 0),
z = c(zlim[1], zlim[2], zlim[2], zlim[1]))
# Add bounding box decoration
if(show.bbox){
rgl.bbox(color=c(bbox.col[1],bbox.col[2]), alpha = 0.5,
emission=bbox.col[1], specular=bbox.col[1], shininess=5,
xlen = 3, ylen = 3, zlen = 3)
}
}
# Ejemplo que ilustra el modelo de clasificación usando una variable
ç
library(rgl)
#' @param new.device a logical value. If TRUE, creates a new device
#' @param bg the background color of the device
#' @param width the width of the device
rgl_init <- function(new.device = FALSE, bg = "white", width = 640) {
if( new.device | rgl.cur() == 0 ) {
rgl.open()
par3d(windowRect = 50 + c( 0, 0, width, width ) )
rgl.bg(color = bg )
}
rgl.clear(type = c("shapes", "bboxdeco"))
rgl.viewpoint(theta = 15, phi = 20, zoom = 0.7)
}
# x, y, z : numeric vectors corresponding to
#  the coordinates of points
# axis.col : axis colors
# xlab, ylab, zlab: axis labels
# show.plane : add axis planes
# show.bbox : add the bounding box decoration
# bbox.col: the bounding box colors. The first color is the
# the background color; the second color is the color of tick marks
rgl_add_axes <- function(x, y, z, axis.col = "grey",
xlab = "", ylab="", zlab="", show.plane = TRUE,
show.bbox = FALSE, bbox.col = c("#333377","black"))
{
lim <- function(x){c(-max(abs(x)), max(abs(x))) * 1.1}
# Add axes
xlim <- lim(x); ylim <- lim(y); zlim <- lim(z)
rgl.lines(xlim, c(0, 0), c(0, 0), color = axis.col)
rgl.lines(c(0, 0), ylim, c(0, 0), color = axis.col)
rgl.lines(c(0, 0), c(0, 0), zlim, color = axis.col)
# Add a point at the end of each axes to specify the direction
axes <- rbind(c(xlim[2], 0, 0), c(0, ylim[2], 0),
c(0, 0, zlim[2]))
rgl.points(axes, color = axis.col, size = 3)
# Add axis labels
rgl.texts(axes, text = c(xlab, ylab, zlab), color = axis.col,
adj = c(0.5, -0.8), size = 2)
# Add plane
if(show.plane)
xlim <- xlim/1.1; zlim <- zlim /1.1
rgl.quads( x = rep(xlim, each = 2), y = c(0, 0, 0, 0),
z = c(zlim[1], zlim[2], zlim[2], zlim[1]))
# Add bounding box decoration
if(show.bbox){
rgl.bbox(color=c(bbox.col[1],bbox.col[2]), alpha = 0.5,
emission=bbox.col[1], specular=bbox.col[1], shininess=5,
xlen = 3, ylen = 3, zlen = 3)
}
}
# Ejemplo que ilustra el modelo de clasificación usando una variable
datos <-data.frame(y=as.numeric(as.numeric(iris$Species)),
x4=iris$Sepal.Width,
x1=iris$Sepal.Length,
x2=iris$Petal.Length,
x3=iris$Petal.Width)
library(splines)
model3 <- glm(y~ns(x2,16), data =datos)
b <- predict(model3, datos)
rb <- round(b)
x <- seq(1,7,0.01)
x <- rbind(x2=x,y=0)
x <-t(x)
x <-as.data.frame(x)
xy <- predict(model3, newdata = x)
rxy <-round(xy)
plot(datos$x2, datos$y, col = datos$y, xlab = "Longitud del Sépalo", ylab = "Tipo de Iris", title("Specie ~ ns(Petal.Length,16)"))
lines(x[,1],xy,col=ifelse(xy<=1.5, "black", ifelse(xy<=2.5, "red", "green")))
segments(datos$x2,datos$y,datos$x2,b, col=datos$y, lty=4)
abline(2.5,0,col="green")
abline(1.5,0,col="red")
# Ejemplo que ilustra el modelo de clasificación en base a 2 variables
model3 <- glm(y~ns(x2,16)+ns(x1,16), data =datos)
c <- predict(model3, newdata = datos)
plot(datos$x2,datos$x1,col=round(c),pch=0,
xlab = "Longitud del Sépalo", ylab = "Longitud del Pétalo", title("Specie ~ ns(Petal.Length,16)+ns(Sepal.Length,16)"))
points(datos$x2,datos$x1,col=datos$y,pch="x")
#### Ilustrar como se distribuye los espacios de clasificación
plantilla <-matrix(c(0,0,0),ncol=3)
for (p1 in seq(1,8,0.05))
for (p2 in seq(1,7,0.05))
plantilla <-rbind(plantilla, c(x1=p1,x2=p2,y=0))
plantilla <- as.data.frame(plantilla)
plantilla[,3] <- predict(model3, newdata = plantilla)
plot(datos$x2,datos$x1,col=round(c),pch=0,
xlab = "Longitud del Sépalo", ylab = "Longitud del Pétalo", title("Specie ~ ns(Petal.Length,16)+ns(Sepal.Length,16)"))
points(plantilla$x2,plantilla$x1,
col= ifelse(round(plantilla$y)<1, 0, ifelse(round(plantilla$y)>3, 0, round(plantilla$y) )),pch=20)
points(datos$x2,datos$x1,col=round(c),pch=0)
points(datos$x2,datos$x1,col=datos$y,pch="x")
# Ejemplo que ilustra el modelo de clasificación en base a 3 variables
model3 <- glm(y~ns(x2,16)+ns(x1,16)+ns(x3,16), data =datos)
c <- predict(model3, newdata = datos)
plantilla <-matrix(c(0,0,0,0),ncol=4)
for (p1 in seq(1,8,(8-1)/10))
for (p2 in seq(1,7,(7-1)/10))
for (p3 in seq(0, 2.5, 2.5/10 ))
plantilla <-rbind(plantilla, c(x1=p1,x2=p2,x3=p3,y=0))
plantilla <- as.data.frame(plantilla)
plantilla[,4] <- round(predict(model3, newdata = plantilla))
plantilla[,4] <- ifelse(plantilla[,4]<1,"white", ifelse(plantilla[,4]>3,"white",plantilla[,4]))
#saca la grafica en 3d
library(rgl)
rgl_init()
rgl.spheres(x=datos$x2, y=datos$x1, z=datos$x3, r=0.1, col=datos$y)
rgl_add_axes(x=datos$x2, y=datos$x1, z=datos$x3, show.bbox = T)
aspect3d(1,1,1)
#### Ilustra como se distribuyen los espacios de clasificación
rgl_init()
rgl.spheres(x=plantilla[,1], y=plantilla[,2], z=plantilla[,3], r=0.1, col=plantilla[,4])
#rgl_add_axes(x=plantilla[,1], y=plantilla[,2], z=plantilla[,3], show.bbox = T)
aspect3d(1,1,1)
plot3d(x=plantilla[,1], y=plantilla[,2], z=plantilla[,3], col=plantilla[,4])
rgl_init()
rgl.spheres(x=plantilla[,1], y=plantilla[,2], z=plantilla[,3], r=0.1, col=plantilla[,4])
rgl_add_axes(x=plantilla[,1], y=plantilla[,2], z=plantilla[,3], show.bbox = T)
aspect3d(1,1,1)
plot3d(x=plantilla[,1], y=plantilla[,2], z=plantilla[,3], col=plantilla[,4])
library(tree)
summary(iris)
# Construir un arbol que clasifica la especie en base al resto de variables
tree.iris = tree(Species~.,iris)
library(tree)
install.packages("tree")
summary(iris)
# Construir un arbol que clasifica la especie en base al resto de variables
tree.iris = tree(Species~.,iris)
library(tree)
summary(iris)
# Construir un arbol que clasifica la especie en base al resto de variables
tree.iris = tree(Species~.,iris)
summary(tree.iris)
plot(tree.iris)
text(tree.iris, pretty=0)
tree.iris
# Dividir en training y test
set.seed (2)
train=sample (1:nrow(iris), 100)
iris.test=iris [-train ,]
# Construyo el arbol sobre el conjunto de entrenamiento
tree.iris =tree(Species~. ,iris ,subset =train )
# Aplico el arbol sobre el conjunto de test
tree.pred =predict (tree.iris ,iris.test ,type ="class")
# Visualizo la matriz de confusion
table(tree.pred , iris.test[,5])
# Podar el arbol usando cv
set.seed (3)
cv.iris = cv.tree(tree.iris ,FUN=prune.misclass )
names(cv.iris )
cv.iris
# Pintamos el error
par(mfrow =c(1,2))
plot(cv.iris$size ,cv.iris$dev ,type="b")
plot(cv.iris$k ,cv.iris$dev ,type="b")
# Ahora podamos el arbol con prune.misclass
prune.iris =prune.misclass (tree.iris ,best =3)
par(mfrow =c(1,1))
plot(prune.iris)
text(prune.iris ,pretty =0)
# Como se comportara este arbol en su capacidad de prediccion
tree.pred=predict (prune.iris , iris.test ,type="class")
table(tree.pred ,iris.test[,5])
# Ahora podemos modificar el tamanio del arbol modificando best
prune.iris =prune.misclass (tree.iris ,best =4)
plot(prune.iris)
text(prune.iris ,pretty =0)
tree.pred=predict (prune.iris , iris.test ,type="class")
table(tree.pred ,iris.test[,5])
# Random Forest
library (randomForest)
set.seed (1)
bag.iris = randomForest(Species~., data=iris, subset=train)
bag.iris
yhat.bag = predict (bag.iris ,newdata =iris.test)
yhat.bag
# Construyo una funcion para calcular el acierto a partir del RandomForest
acierto <- function(bag.datos){
return (sum (sapply(1:length(bag.datos$y), function(x){
if (is.na(bag.datos$predicted[x])){
0
}
else if (as.numeric(bag.datos$y[x])==as.numeric(bag.datos$predicted[x])){
1
}
else{
0
}
}))/length(bag.datos$y))
}
resul = as.data.frame(cbind(predicted = yhat.bag, y=iris.test[,5]))
acierto(resul)
# Fijando el numero de arboles
bag.iris = randomForest(Species~.,data=iris ,subset =train , ntree=25)
bag.iris
acierto(bag.iris)
bag.func = randomForest(formula,data=datos,ntree=num_trees)
bag.func = randomForest(formula,data=datos,subset=train,ntree=num_trees)
Graphical_RF <- function(datos, formula, num_trees){
# Definir aqui la funcion
bag.func = randomForest(formula,data=datos,subset=train,ntree=num_trees)
acierto(bag.func)
}
Graphical_RF(iris,Species~.,100)
Graphical_RF <- function(datos, formula, num_trees){
# Definir aqui la funcion
sapply(1:num_trees, function(x){
bag.func = randomForest(formula,data=datos,subset=train,ntree=x)
acierto(bag.func)
})
}
Graphical_RF(iris,Species~.,100)
Graphical_RF <- function(datos, formula, num_trees){
# Definir aqui la funcion
vec <- sapply(1:num_trees, function(x){
bag.func = randomForest(formula,data=datos,subset=train,ntree=x)
acierto(bag.func)
})
}
Graphical_RF(iris,Species~.,100)
vec
Graphical_RF <- function(datos, formula, num_trees){
# Definir aqui la funcion
vec <- sapply(1:num_trees, function(x){
bag.func = randomForest(formula,data=datos,subset=train,ntree=x)
acierto(bag.func)
})
vec
}
Graphical_RF(iris,Species~.,100)
Graphical_RF <- function(datos, formula, num_trees){
# Definir aqui la funcion
vec <- sapply(1:num_trees, function(x){
bag.func = randomForest(formula,data=datos,subset=train,ntree=x)
acierto(bag.func)
})
plot(1:num_trees,vec)
}
Graphical_RF(iris,Species~.,100)
lines()
lines(vec)
Graphical_RF <- function(datos, formula, num_trees){
# Definir aqui la funcion
vec <- sapply(1:num_trees, function(x){
bag.func = randomForest(formula,data=datos,subset=train,ntree=x)
acierto(bag.func)
})
plot(1:num_trees,vec)
lines(vec)
}
Graphical_RF(iris,Species~.,100)
summary(iris)
summary(Auto)
Auto
Autos
summary(Autos)
library(ISLR)
summary(Autos)
summary(Auto)
dim(Auto)
dim(iris)
set.seed (2)
train=sample (1:nrow(Auto), 300)
datos = Auto
Graphical_RF(datos,origin~.-name,100)
train=sample (1:nrow(iris), 100)
set.seed (2)
train=sample (1:nrow(iris), 100)
setwd("~/Dropbox/zMaster/zRStudio/Master-en-Ciencia-De-Datos-e-Ingeniería-de-Computadores-2/3 Mineria de Datos, Aspectos Avanzados/Clasificacion con conjuntos de datos no balanceados, no equilibrados")
